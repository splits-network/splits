---
phase: 15-production-hardening
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - services/api-gateway/src/routes/v2/gpt.ts
autonomous: true

must_haves:
  truths:
    - "GPT read endpoints (job search, job details, application status) are rate limited to 30 requests/min per user"
    - "GPT expensive endpoints (resume analysis, application submission) are rate limited to 10 requests/min per user"
    - "Rate limited requests return 429 with Retry-After header"
    - "Rate limiting is per-user (keyed by GPT Bearer token), not per-IP"
  artifacts:
    - path: "services/api-gateway/src/routes/v2/gpt.ts"
      provides: "GPT route handlers with per-user tiered rate limiting"
      contains: "rateLimit"
  key_links:
    - from: "services/api-gateway/src/routes/v2/gpt.ts"
      to: "services/api-gateway/src/index.ts"
      via: "Redis instance passed to GPT route registration for rate limit storage"
      pattern: "redis"
---

<objective>
Add GPT-specific per-user tiered rate limiting in api-gateway to prevent abuse of expensive endpoints.

Purpose: Protect GPT endpoints from excessive usage with appropriate per-user limits (30 req/min reads, 10 req/min writes).
Output: Updated GPT route handlers with @fastify/rate-limit route-level overrides.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/15-production-hardening/15-CONTEXT.md

@services/api-gateway/src/routes/v2/gpt.ts
@services/api-gateway/src/routes/v2/routes.ts
@services/api-gateway/src/index.ts
@services/api-gateway/package.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add GPT-specific per-user tiered rate limiting</name>
  <files>
    services/api-gateway/src/routes/v2/gpt.ts
    services/api-gateway/src/routes/v2/routes.ts
  </files>
  <action>
    The api-gateway already has `@fastify/rate-limit` registered globally (500 req/min authenticated, 100 req/min unauthenticated). Fastify's rate-limit plugin supports route-level config overrides via the `config` property on route options. We need tighter per-user limits specifically for GPT routes.

    **Approach: Use Fastify route-level rate limit config overrides.**

    The `@fastify/rate-limit` plugin (already registered in index.ts) supports route-level overrides. Each route can specify `config: { rateLimit: { max, timeWindow, keyGenerator } }` to override the global rate limit for that specific route.

    **1. Update `services/api-gateway/src/routes/v2/gpt.ts`:**

    - Accept `redis` (Redis instance) as a new parameter in `registerGptRoutes`:
      ```typescript
      export function registerGptRoutes(app: FastifyInstance, services: ServiceRegistry, redis?: Redis)
      ```
    - Import `Redis` from `ioredis`

    - Define two rate limit config objects at the top of the function:

      ```typescript
      // GPT read endpoints: 30 requests/min per user
      const gptReadRateLimit = {
          rateLimit: {
              max: 30,
              timeWindow: '1 minute',
              keyGenerator: (request: any) => {
                  const auth = request.headers['authorization'];
                  if (auth) return `gpt-read:${auth.slice(-16)}`;
                  return `gpt-read:${request.ip}`;
              },
          },
      };

      // GPT write/expensive endpoints: 10 requests/min per user
      const gptWriteRateLimit = {
          rateLimit: {
              max: 10,
              timeWindow: '1 minute',
              keyGenerator: (request: any) => {
                  const auth = request.headers['authorization'];
                  if (auth) return `gpt-write:${auth.slice(-16)}`;
                  return `gpt-write:${request.ip}`;
              },
          },
      };
      ```

    - Apply `gptReadRateLimit` as route `config` to:
      - GET `/api/v1/gpt/oauth/authorize` (OAuth authorization)
      - POST `/api/v1/gpt/oauth/token` (token exchange)
      - POST `/api/v1/gpt/oauth/revoke` (session revocation)
      - GET `/api/v1/gpt/*` wildcard (covers job search, job details, application status)

    - Apply `gptWriteRateLimit` as route `config` to:
      - POST `/api/v1/gpt/*` wildcard (covers application submission, resume analysis)

    - To apply config, change route registrations from:
      ```typescript
      app.get('/api/v1/gpt/oauth/authorize', async (request, reply) => { ... });
      ```
      to:
      ```typescript
      app.get('/api/v1/gpt/oauth/authorize', { config: gptReadRateLimit }, async (request, reply) => { ... });
      ```
      Apply the same pattern to all 5 route registrations.

    **2. Update `services/api-gateway/src/routes/v2/routes.ts`:**
    - Update `registerGptRoutes` call to pass the redis instance:
      ```typescript
      registerGptRoutes(app, services, options?.redis);
      ```
    - Update the import signature does not need changing (the function signature update in gpt.ts handles this)

    **Important notes:**
    - The global rate limit still applies as a ceiling (500/min authenticated). The GPT-specific limits are tighter subsets.
    - The key prefixes `gpt-read:` and `gpt-write:` ensure GPT rate limit buckets are separate from each other and from global buckets.
    - The `Retry-After` header is automatically included by @fastify/rate-limit when returning 429 responses.
    - OAuth endpoints (authorize, token, revoke) use the read limit since they are not expensive.
  </action>
  <verify>
    - `services/api-gateway/src/routes/v2/gpt.ts` contains `rateLimit` config on all 5 route registrations
    - GET routes use max: 30, POST `/api/v1/gpt/*` uses max: 10
    - Key generator prefixes are `gpt-read:` and `gpt-write:`
    - `routes.ts` passes redis to `registerGptRoutes`
    - Build check: `pnpm --filter @splits-network/api-gateway build` succeeds
  </verify>
  <done>
    GPT routes have per-user tiered rate limits: 30 req/min for reads, 10 req/min for expensive writes. Rate limits key on Bearer token suffix to isolate per-user buckets. 429 responses include Retry-After header automatically.
  </done>
</task>

</tasks>

<verification>
- `pnpm --filter @splits-network/api-gateway build` succeeds
- GPT GET wildcard route has `config: gptReadRateLimit` with max: 30
- GPT POST wildcard route has `config: gptWriteRateLimit` with max: 10
- OAuth routes have `config: gptReadRateLimit` with max: 30
- Rate limit key generators use `gpt-read:` and `gpt-write:` prefixes
</verification>

<success_criteria>
- All 5 GPT route registrations have route-level rate limit config
- Read endpoints: 30 requests/min per user
- Write endpoints: 10 requests/min per user
- Rate limiting keyed per-user via Bearer token suffix
- api-gateway builds successfully
</success_criteria>

<output>
After completion, create `.planning/phases/15-production-hardening/15-02-SUMMARY.md`
</output>

---
phase: 13-gpt-api-endpoints
plan: 04
type: execute
wave: 2
depends_on: ["13-01"]
files_modified:
  - services/gpt-service/src/v2/actions/routes.ts
autonomous: true

must_haves:
  truths:
    - "Resume analysis endpoint accepts optional resume_text from GPT and falls back to stored resume"
    - "Resume analysis returns fit score, strengths, gaps, and recommendation from ai-service"
    - "If no resume available (neither provided nor stored), returns error with guidance to upload"
  artifacts:
    - path: "services/gpt-service/src/v2/actions/routes.ts"
      provides: "POST /api/v2/resume/analyze route handler that calls ai-service for fit analysis"
      min_lines: 40
  key_links:
    - from: "services/gpt-service/src/v2/actions/routes.ts"
      to: "ai-service /api/v2/ai-reviews"
      via: "HTTP fetch call to ai-service"
      pattern: "fetch.*ai.*service.*ai-reviews"
    - from: "services/gpt-service/src/v2/actions/routes.ts"
      to: "services/gpt-service/src/v2/actions/repository.ts"
      via: "getCandidateResume for fallback"
      pattern: "repository\\.getCandidateResume"
---

<objective>
Implement the resume analysis endpoint that accepts optional resume text from GPT (extracted from user-uploaded file in chat) or falls back to stored resume, then calls ai-service for server-side fit analysis against a specific job posting.

Purpose: ENDP-06 (resume analysis), ENDP-07 (candidate-scoped auth). This endpoint leverages the existing ai-service AI review infrastructure for consistent scoring. The GPT passes extracted text as a string parameter rather than file upload.

Output: POST /api/v2/resume/analyze handler added to routes.ts
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/13-gpt-api-endpoints/13-CONTEXT.md

@services/ai-service/src/v2/reviews/routes.ts
@services/ai-service/src/v2/reviews/service.ts
@services/gpt-service/src/v2/oauth/middleware.ts

Reference Plan 01 SUMMARY for types, repository, and helpers.
Reference Plan 02 SUMMARY for existing route structure.
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement POST /api/v2/resume/analyze with ai-service integration</name>
  <files>
    services/gpt-service/src/v2/actions/routes.ts
  </files>
  <action>
Add route to the existing `registerActionRoutes` function in `services/gpt-service/src/v2/actions/routes.ts`.

**Route: POST /api/v2/resume/analyze**
- Scope: `resume:read` (reading/analyzing resume, not writing)
- PreHandler: `[extractGptAuth(oauthService), requireScope('resume:read')]`
- Body: GptResumeAnalysisRequest (job_id: string, resume_text?: string)

**Handler logic:**

1. Get clerkUserId from `request.gptAuth!.clerkUserId`
2. Resolve candidateId via `repository.resolveCandidateId(clerkUserId)`
   - If no candidateId: 404 with `gptError('NOT_FOUND', 'No candidate profile found', { suggestion: 'Create a profile at applicant.network/portal/profile' })`
3. Validate job_id is present
   - If missing: 400 with `gptError('INVALID_REQUEST', 'job_id is required')`
4. Validate job exists: `repository.getJobDetail(job_id)`
   - If null: 404 with `gptError('NOT_FOUND', 'Job not found or no longer active')`
5. **Resolve resume text** (priority order):
   a. If `resume_text` provided in request body, use it directly (GPT extracted from user file)
   b. Else, try stored resume: `repository.getCandidateResume(candidateId)`
      - If document found with `metadata.extracted_text`, use that text
   c. If neither available: 400 with `gptError('RESUME_NOT_FOUND', 'No resume available for analysis. Please either upload your resume in the chat, or upload it to your profile.', { suggestion: 'Upload your resume at applicant.network/portal/profile' })`
6. **Call ai-service for analysis:**
   - Use `fetch()` to call ai-service's review endpoint: `POST ${AI_SERVICE_URL}/api/v2/ai-reviews`
   - AI_SERVICE_URL from environment: `process.env.AI_SERVICE_URL || 'http://ai-service:3010'` (read this at the top of registerActionRoutes, not per-request)
   - Request body:
     ```json
     {
       "application_id": "gpt-analysis-{uuid}",
       "candidate_id": candidateId,
       "job_id": job_id,
       "resume_text": resolvedResumeText,
       "job_description": job.description,
       "job_title": job.title,
       "required_skills": job.requirements?.filter(r => r.requirement_type === 'mandatory').map(r => r.description) || [],
       "preferred_skills": job.requirements?.filter(r => r.requirement_type === 'preferred').map(r => r.description) || [],
       "candidate_location": null,
       "job_location": job.location
     }
     ```
   - Headers: `{ 'Content-Type': 'application/json', 'x-internal-service-key': process.env.INTERNAL_SERVICE_KEY || '' }`
   - Note: Use a synthetic application_id with `gpt-analysis-` prefix since this is not tied to an actual application. The ai-service `enrichInputIfNeeded` will skip fetching application data since we provide all fields directly.
7. **Parse ai-service response:**
   - If response not OK: 500 with `gptError('INTERNAL_ERROR', 'Resume analysis failed. Please try again.')`
   - Parse JSON response: `{ data: review }`
   - Map to GptResumeAnalysisResponse:
     - fit_score: review.fit_score (0-100)
     - strengths: review.strengths (string array)
     - gaps: review.concerns || review.missing_skills (whichever provides more useful info -- use concerns as primary, they're more descriptive)
     - recommendation: review.recommendation (strong_fit/good_fit/fair_fit/poor_fit)
     - overall_summary: review.overall_summary
8. **Publish audit event** (if eventPublisher available):
   ```
   eventPublisher.publish('gpt.action.resume_analyzed', {
     candidate_id: candidateId,
     job_id: job_id,
     fit_score: review.fit_score,
     clerk_user_id: clerkUserId,
     resume_source: resume_text ? 'gpt_upload' : 'stored',
   })
   ```
9. Return 200 with:
   ```json
   {
     "data": {
       "fit_score": 75,
       "strengths": ["5+ years React experience", "..."],
       "gaps": ["No Kubernetes experience mentioned", "..."],
       "recommendation": "good_fit",
       "overall_summary": "The candidate shows strong frontend skills..."
     }
   }
   ```

**Error handling:** Wrap in try/catch. Log errors with request.log.error. Return 500 with gptError on unexpected failures. Specifically catch fetch errors (ai-service unreachable) and return a user-friendly error.

**Environment variable:** The AI_SERVICE_URL should be read once at the top of registerActionRoutes (not per request). Check ai-service's port from `services/ai-service/.env` or default patterns.
  </action>
  <verify>
    Run `cd g:/code/splits.network && npx tsc --noEmit --project services/gpt-service/tsconfig.json` -- should compile without errors.
  </verify>
  <done>
    POST /api/v2/resume/analyze accepts optional resume_text, falls back to stored resume, calls ai-service for analysis, and returns fit score + strengths + gaps + recommendation. Audit events published on analysis completion.
  </done>
</task>

</tasks>

<verification>
- `npx tsc --noEmit --project services/gpt-service/tsconfig.json` passes
- POST /api/v2/resume/analyze route is registered with resume:read scope
- Resume text priority: request body > stored document > error with guidance
- ai-service called with correct payload including job requirements
- Response maps ai-service review to GptResumeAnalysisResponse shape
- Error handling covers: no candidate, no job, no resume, ai-service failure
</verification>

<success_criteria>
Resume analysis endpoint works end-to-end: accepts GPT-provided resume text or retrieves stored resume, calls ai-service for server-side analysis, and returns structured fit assessment. Error messages guide users to upload their resume if missing.
</success_criteria>

<output>
After completion, create `.planning/phases/13-gpt-api-endpoints/13-04-SUMMARY.md`
</output>

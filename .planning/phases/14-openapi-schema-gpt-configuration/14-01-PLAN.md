---
phase: 14-openapi-schema-gpt-configuration
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - services/gpt-service/src/openapi.yaml
  - services/gpt-service/src/openapi-route.ts
  - services/gpt-service/src/v2/routes.ts
  - services/api-gateway/src/routes/v2/gpt.ts
autonomous: true

must_haves:
  truths:
    - "OpenAPI 3.0.1 schema defines all 5 GPT Action endpoints with operationIds, parameter descriptions, response schemas, and OAuth2 security scheme"
    - "Schema is served at /api/v1/gpt/openapi.yaml and /api/v1/gpt/openapi.json"
    - "All write action operations are annotated with x-openai-isConsequential: true"
    - "All valid enum values are included in schema (commute_type, job_level, stage labels)"
  artifacts:
    - path: "services/gpt-service/src/openapi.yaml"
      provides: "Complete OpenAPI 3.0.1 schema for all GPT Actions"
      min_lines: 300
    - path: "services/gpt-service/src/openapi-route.ts"
      provides: "Route handler serving schema at /api/v2/openapi.yaml and /api/v2/openapi.json"
      min_lines: 20
  key_links:
    - from: "services/gpt-service/src/openapi-route.ts"
      to: "services/gpt-service/src/openapi.yaml"
      via: "fs.readFileSync at startup"
      pattern: "readFileSync.*openapi\\.yaml"
    - from: "services/gpt-service/src/v2/routes.ts"
      to: "services/gpt-service/src/openapi-route.ts"
      via: "registerOpenapiRoute import and call"
      pattern: "registerOpenapiRoute"
    - from: "services/api-gateway/src/routes/v2/gpt.ts"
      to: "gpt-service /api/v2/openapi"
      via: "wildcard GET /api/v1/gpt/* proxy"
      pattern: "api/v1/gpt/\\*"
---

<objective>
Create the complete OpenAPI 3.0.1 schema defining all 5 GPT Action endpoints and serve it at /api/v1/gpt/openapi.yaml (and .json) through the api-gateway proxy.

Purpose: The OpenAPI schema is what GPT Builder imports to discover available actions. Without it, the Custom GPT cannot be configured. Rich descriptions guide GPT on when/how to use each endpoint.
Output: Static openapi.yaml file with all endpoints, parameters, response schemas, OAuth2 security, and x-openai-isConsequential annotations. Serving route for YAML and JSON formats.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/14-openapi-schema-gpt-configuration/14-CONTEXT.md

# Source of truth for endpoint shapes
@services/gpt-service/src/v2/actions/types.ts
@services/gpt-service/src/v2/actions/routes.ts
@services/gpt-service/src/v2/actions/helpers.ts
@services/gpt-service/src/v2/oauth/types.ts

# Route registration pattern
@services/gpt-service/src/v2/routes.ts
@services/gpt-service/src/index.ts

# Gateway proxy pattern (wildcard already handles GET /api/v1/gpt/*)
@services/api-gateway/src/routes/v2/gpt.ts

# Enum values
@packages/shared-types/src/models.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create OpenAPI 3.0.1 schema file</name>
  <files>services/gpt-service/src/openapi.yaml</files>
  <action>
Create a hand-crafted OpenAPI 3.0.1 schema file at services/gpt-service/src/openapi.yaml defining all 5 GPT Action endpoints. This is a STATIC file checked into the repo, NOT auto-generated.

**Info section:**
- openapi: 3.0.1
- title: "Applicant Network Career Copilot API"
- description: "API for Career Copilot GPT -- search jobs, check applications, submit applications, and analyze resume fit."
- version: "1.0.0"

**Server:**
- url: https://api.splits.network (production gateway URL)

**Security scheme (in components/securitySchemes):**
- Type: oauth2
- Authorization URL: https://api.splits.network/api/v1/gpt/oauth/authorize
- Token URL: https://api.splits.network/api/v1/gpt/oauth/token
- Scopes: jobs:read ("Search and view job listings"), applications:read ("View your application status"), applications:write ("Submit job applications"), resume:read ("Analyze resume fit against jobs")

**Apply security globally:** security: [{ oauth2: [jobs:read, applications:read, applications:write, resume:read] }]

**Paths (5 endpoints) -- All paths use the /api/v1/gpt/ prefix (gateway-facing URLs):**

1. **GET /api/v1/gpt/jobs/search**
   - operationId: searchJobs
   - summary: "Search for job openings"
   - description: Rich behavioral hint -- "Search for jobs matching keywords, location, commute preferences, and experience level. Returns up to 5 results per page. Use this when the candidate asks to find jobs, look for opportunities, or mentions specific roles, skills, or locations. If no results, suggest broadening the search criteria."
   - Parameters (all query, optional):
     - keywords (string): "Search terms to match against job titles, descriptions, and skills. Examples: 'software engineer', 'remote python developer', 'marketing manager'"
     - location (string): "City, state, or region to filter by. Examples: 'San Francisco', 'New York, NY', 'Remote'"
     - commute_type (string, enum: [remote, hybrid_1, hybrid_2, hybrid_3, hybrid_4, in_office]): "Filter by work arrangement. hybrid_1 through hybrid_4 indicates days in office per week."
     - job_level (string, enum: [entry, mid, senior, lead, manager, director, vp, c_suite]): "Filter by seniority level"
     - page (integer, default 1): "Page number for pagination. Each page returns 5 results."
   - Response 200: data envelope with jobs array (GptJobSearchResult schema) and pagination object
   - Response 401: OAuth token error
   - Response 500: Server error

2. **GET /api/v1/gpt/jobs/{id}**
   - operationId: getJobDetails
   - summary: "Get full details for a specific job"
   - description: "Retrieve comprehensive job information including description, requirements, pre-screen questions, salary, and company details. Use this when the candidate wants to learn more about a specific job from search results, or asks about a job they've seen."
   - Parameters: id (path, required, string format uuid): "The unique job identifier (UUID format)"
   - Response 200: data envelope with GptJobDetail schema
   - Response 400: Invalid job ID format
   - Response 404: Job not found
   - Response 500: Server error

3. **GET /api/v1/gpt/applications**
   - operationId: getApplications
   - summary: "Check your application status"
   - description: "List the candidate's job applications with current status. Shows active applications by default (Interview, Under Review, Submitted, etc.). Use this when the candidate asks about their applications, wants to check status, or says 'what's happening with my applications?'"
   - Parameters (all query, optional):
     - include_inactive (boolean, default false): "Set to true to include completed/closed applications (Hired, Not Selected, Withdrawn)"
     - page (integer, default 1): "Page number. Each page returns 10 applications."
   - Response 200: data envelope with applications array (GptApplicationStatus schema) and pagination
   - Response 404: No candidate profile
   - Response 500: Server error

4. **POST /api/v1/gpt/applications/submit**
   - operationId: submitApplication
   - summary: "Submit a job application"
   - description: "Two-step application submission with confirmation safety. First call (confirmed omitted or false): validates the job, checks for duplicates, validates pre-screen answers, and returns a confirmation summary with a token. Second call (confirmed=true with token): executes the submission. IMPORTANT: Always show the confirmation summary to the candidate and wait for their explicit approval before making the second call."
   - **x-openai-isConsequential: true**
   - Request body (application/json, required):
     - job_id (string, required): "UUID of the job to apply to"
     - confirmed (boolean): "Set to true on the second call to execute submission. Omit or set to false for initial confirmation request."
     - confirmation_token (string): "Token from the first call's response. Required when confirmed=true."
     - pre_screen_answers (array of objects with question_id string and answer string): "Answers to required pre-screen questions. Each answer pairs a question_id with the candidate's response."
     - cover_letter (string): "Optional cover letter text"
   - Response 200: CONFIRMATION_REQUIRED with summary (first call)
   - Response 201: Application submitted (second call)
   - Response 400: Missing pre-screen answers / invalid token
   - Response 404: Job or candidate not found
   - Response 409: Duplicate application (includes original application date)
   - Response 500: Server error

5. **POST /api/v1/gpt/resume/analyze**
   - operationId: analyzeResume
   - summary: "Analyze resume fit against a job"
   - description: "Analyze how well the candidate's resume matches a specific job posting. Returns a fit score (0-100), strengths, gaps, and actionable recommendations. The candidate can paste resume text directly in chat (passed via resume_text parameter) or use their stored profile resume. Use this when the candidate asks about their fit for a job, wants resume feedback, or you want to proactively suggest a fit check after showing job details."
   - **x-openai-isConsequential: false** (read-only analysis, no state change)
   - Request body (application/json, required):
     - job_id (string, required): "UUID of the job to analyze fit against"
     - resume_text (string): "Resume text pasted by the candidate in chat. If omitted, the stored profile resume is used."
   - Response 200: data envelope with GptResumeAnalysisResponse schema (fit_score, strengths, gaps, recommendation, overall_summary)
   - Response 400: No resume available / invalid request
   - Response 404: Job or candidate not found
   - Response 500: Server error / AI service unavailable

**Components/schemas (use $ref for reuse):**

Define these schemas in components/schemas:
- GptJobSearchResult: { id, title, company_name, location, commute_types, posted_date, salary_range, job_level, summary } -- with descriptions for each field
- GptJobDetail: extends GptJobSearchResult with { description, responsibilities, requirements array, pre_screen_questions array, company object }
- GptApplicationStatus: { id, job_title, company_name, status_label, applied_date, last_updated }
- GptConfirmationSummary: { confirmation_token, expires_at, job_title, company_name, requirements_summary, pre_screen_answers_provided, missing_required_questions, warnings }
- GptResumeAnalysisResponse: { fit_score, strengths, gaps, recommendation, overall_summary }
- GptErrorResponse: { error: { code, message, suggestion } }
- PaginationInfo: { page, total_pages, total_results }

**Key details:**
- Use OpenAPI 3.0.1 (NOT 3.1 -- GPT Builder only supports 3.0.x as of early 2025)
- All response schemas use the { data: ... } envelope pattern
- Include description fields on EVERY property with meaningful context
- salary_range uses nullable: true (can be null when salary not disclosed)
- commute_types is an array of strings with enum values
- posted_date and applied_date are date strings in YYYY-MM-DD format
- status_label values documented: "Submitted", "Under Review", "Interviewing", "Offer Received", "Hired", "Not Selected", "Withdrawn", "Screening", "Recruiter Proposed", "Changes Requested"
  </action>
  <verify>
Validate the YAML syntax: `npx yaml "services/gpt-service/src/openapi.yaml"` or manually verify YAML parses without errors. Confirm all 5 paths exist, both write operations have x-openai-isConsequential, OAuth2 security scheme is defined, and all enum values match shared-types (6 commute types, 8 job levels).
  </verify>
  <done>
OpenAPI 3.0.1 schema file exists with all 5 GPT Action endpoints fully defined including operationIds, rich descriptions, parameter examples, complete response schemas with $ref components, OAuth2 security scheme, and x-openai-isConsequential on write actions (submitApplication=true, analyzeResume=false).
  </done>
</task>

<task type="auto">
  <name>Task 2: Create schema serving endpoint and wire into service</name>
  <files>
    services/gpt-service/src/openapi-route.ts
    services/gpt-service/src/v2/routes.ts
  </files>
  <action>
Create a route handler that serves the OpenAPI schema in both YAML and JSON formats.

**File: services/gpt-service/src/openapi-route.ts**

```typescript
import { FastifyInstance } from 'fastify';
import { readFileSync } from 'fs';
import { join } from 'path';
import { load } from 'js-yaml';
```

- Read openapi.yaml at module load time using readFileSync (path: join(__dirname, 'openapi.yaml'))
- Parse YAML to JSON object using js-yaml's load() function
- Store both raw YAML string and parsed JSON object as module-level constants

Register two routes (no auth required -- schema is public):

1. **GET /api/v2/openapi.yaml** - Returns raw YAML string with content-type: text/yaml
2. **GET /api/v2/openapi.json** - Returns parsed JSON object with content-type: application/json

Export: `registerOpenapiRoute(app: FastifyInstance): void`

**Install js-yaml:** Run `pnpm --filter @splits-network/gpt-service add js-yaml` and `pnpm --filter @splits-network/gpt-service add -D @types/js-yaml`

**File: services/gpt-service/src/v2/routes.ts**

Add import for registerOpenapiRoute from '../openapi-route' and call it after existing route registrations:
```typescript
registerOpenapiRoute(app);
```

**Note on api-gateway:** The wildcard GET /api/v1/gpt/* route in api-gateway already proxies to gpt-service GET /api/v2/*, so /api/v1/gpt/openapi.yaml will automatically proxy to /api/v2/openapi.yaml. No gateway changes needed.

However, verify the gateway wildcard does NOT strip query strings for this path -- it should work since it uses buildQueryString already.
  </action>
  <verify>
1. `pnpm --filter @splits-network/gpt-service build` compiles without errors
2. Verify openapi-route.ts exists and imports openapi.yaml
3. Verify routes.ts calls registerOpenapiRoute
4. Confirm api-gateway wildcard pattern means /api/v1/gpt/openapi.yaml -> /api/v2/openapi.yaml without changes
  </verify>
  <done>
Schema serving endpoint exists at /api/v2/openapi.yaml (YAML) and /api/v2/openapi.json (JSON). Wired into gpt-service route registration. Accessible via api-gateway at /api/v1/gpt/openapi.yaml and /api/v1/gpt/openapi.json through existing wildcard proxy. js-yaml added as dependency.
  </done>
</task>

</tasks>

<verification>
1. openapi.yaml has valid YAML syntax and all 5 endpoint paths
2. Both YAML and JSON serving routes registered
3. gpt-service builds successfully with `pnpm --filter @splits-network/gpt-service build`
4. Schema includes OAuth2 security scheme, x-openai-isConsequential on write ops
5. All enum values match codebase (commute types: remote, hybrid_1-4, in_office; job levels: entry, mid, senior, lead, manager, director, vp, c_suite)
</verification>

<success_criteria>
- OpenAPI 3.0.1 schema file defines all 5 GPT Actions with complete request/response schemas
- Schema served at /api/v2/openapi.yaml and /api/v2/openapi.json
- Gateway proxy maps to /api/v1/gpt/openapi.yaml and .json
- x-openai-isConsequential: true on submitApplication, false on analyzeResume
- gpt-service compiles successfully
</success_criteria>

<output>
After completion, create `.planning/phases/14-openapi-schema-gpt-configuration/14-01-SUMMARY.md`
</output>

---
phase: 11-service-foundation
plan: 03
type: execute
wave: 2
depends_on: ["11-01", "11-02"]
files_modified:
  - services/gpt-service/src/v2/shared/audit-consumer.ts
  - services/gpt-service/src/index.ts
autonomous: true

must_haves:
  truths:
    - "gpt-service publishes gpt.oauth.* events via EventPublisher and a consumer receives them and writes to gpt_oauth_events table"
    - "AuditEventConsumer connects to RabbitMQ, binds to gpt.oauth.# routing pattern, and processes events"
    - "End-to-end event flow works: publish -> RabbitMQ -> consume -> DB write"
  artifacts:
    - path: "services/gpt-service/src/v2/shared/audit-consumer.ts"
      provides: "RabbitMQ consumer that listens for gpt.oauth.* events and writes to gpt_oauth_events table"
      contains: "class AuditEventConsumer"
      min_lines: 60
    - path: "services/gpt-service/src/index.ts"
      provides: "Updated entry point that initializes and connects AuditEventConsumer"
      contains: "AuditEventConsumer"
  key_links:
    - from: "services/gpt-service/src/v2/shared/audit-consumer.ts"
      to: "gpt_oauth_events table"
      via: "Supabase insert on message receive"
      pattern: "supabase.*from.*gpt_oauth_events.*insert"
    - from: "services/gpt-service/src/index.ts"
      to: "services/gpt-service/src/v2/shared/audit-consumer.ts"
      via: "AuditEventConsumer instantiation and connect"
      pattern: "new AuditEventConsumer"
    - from: "services/gpt-service/src/v2/shared/events.ts"
      to: "services/gpt-service/src/v2/shared/audit-consumer.ts"
      via: "RabbitMQ topic exchange (gpt.oauth.* routing key)"
      pattern: "gpt\\.oauth\\."
---

<objective>
Create the AuditEventConsumer for gpt-service that listens for gpt.oauth.* RabbitMQ events and writes them to the gpt_oauth_events database table, completing the end-to-end event flow.

Purpose: Validate the full RabbitMQ pipeline (publish -> consume -> DB write) that will be used for all GPT audit logging. This is not fire-and-forget; the consumer must reliably write events to the database.
Output: A working AuditEventConsumer wired into gpt-service startup, with graceful shutdown.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/11-service-foundation/11-CONTEXT.md
@.planning/phases/11-service-foundation/11-01-SUMMARY.md
@.planning/phases/11-service-foundation/11-02-SUMMARY.md

# Pattern references
@services/ats-service/src/v2/shared/domain-consumer.ts
@services/ats-service/src/index.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create AuditEventConsumer</name>
  <files>services/gpt-service/src/v2/shared/audit-consumer.ts</files>
  <action>
Create an AuditEventConsumer class following the exact pattern of ats-service/src/v2/shared/domain-consumer.ts but simpler -- it only needs to write events to a single table.

**Class structure:**
```typescript
import amqp, { Connection, Channel, ConsumeMessage } from 'amqplib';
import { SupabaseClient, createClient } from '@supabase/supabase-js';
import { Logger } from '@splits-network/shared-logging';

interface DomainEvent {
    event_id: string;
    event_type: string;
    payload: Record<string, any>;
    timestamp: string;
    source_service: string;
}

export class AuditEventConsumer {
    private connection: Connection | null = null;
    private channel: Channel | null = null;
    private supabase: SupabaseClient;
    private readonly exchange = 'splits-network-events';
    private readonly queue = 'gpt-service-audit-events';

    constructor(
        private rabbitMqUrl: string,
        supabaseUrl: string,
        supabaseKey: string,
        private logger: Logger
    ) {
        this.supabase = createClient(supabaseUrl, supabaseKey);
    }
}
```

**connect() method:**
1. Connect to RabbitMQ (same pattern as DomainEventConsumer)
2. Assert topic exchange 'splits-network-events' (durable: true)
3. Assert queue 'gpt-service-audit-events' (durable: true)
4. Bind queue to exchange with routing key `gpt.oauth.#` (wildcard to match all gpt.oauth.* events like gpt.oauth.authorize, gpt.oauth.token_exchange, etc.)
5. Also bind `gpt.action.#` for future action audit events (job_search, resume_analyze, etc.)
6. Start consuming with noAck: false (manual acknowledgment for reliability)

**handleMessage(msg) method:**
1. Parse message body as DomainEvent
2. Extract fields for gpt_oauth_events insert:
   - event_type: event.event_type (e.g., 'gpt.oauth.authorize')
   - clerk_user_id: event.payload.clerk_user_id (may be null)
   - metadata: event.payload (the full payload as JSONB)
   - ip_address: event.payload.ip_address (may be null)
3. Insert into gpt_oauth_events via Supabase client
4. On success: ack the message (this.channel.ack(msg))
5. On failure: log error with full event context, nack the message with requeue: false (dead letter, don't loop)

**disconnect() method:**
1. Close channel, close connection (same pattern as EventPublisher.close)

Use try/catch around all RabbitMQ and DB operations. Log at debug level for successful writes, error level for failures.
  </action>
  <verify>Run `pnpm --filter @splits-network/gpt-service build` and confirm it compiles without errors.</verify>
  <done>AuditEventConsumer class exists with connect, handleMessage, disconnect methods. Listens on gpt.oauth.# and gpt.action.# routing keys. Writes to gpt_oauth_events table.</done>
</task>

<task type="auto">
  <name>Task 2: Wire AuditEventConsumer into gpt-service startup</name>
  <files>services/gpt-service/src/index.ts</files>
  <action>
Update gpt-service/src/index.ts to initialize and connect the AuditEventConsumer, following the ats-service pattern for DomainEventConsumer.

**Changes to index.ts:**

1. Import AuditEventConsumer:
   ```typescript
   import { AuditEventConsumer } from './v2/shared/audit-consumer';
   ```

2. After EventPublisher connects successfully, initialize AuditEventConsumer:
   ```typescript
   const auditConsumer = new AuditEventConsumer(
       rabbitConfig.url,
       dbConfig.supabaseUrl,
       dbConfig.supabaseServiceRoleKey || dbConfig.supabaseAnonKey,
       logger
   );
   ```

3. Connect the consumer (with error handling like ats-service):
   ```typescript
   try {
       await auditConsumer.connect();
       logger.info('RabbitMQ AuditEventConsumer connected successfully');
   } catch (error) {
       logger.error({ err: error }, 'Failed to connect RabbitMQ AuditEventConsumer on startup');
       throw error;
   }
   ```

4. Update SIGTERM handler to disconnect audit consumer:
   ```typescript
   process.on('SIGTERM', async () => {
       logger.info('SIGTERM received, shutting down gracefully');
       await auditConsumer.disconnect();
       await v2EventPublisher.close();
       await app.close();
       process.exit(0);
   });
   ```

5. Update error path in app.listen catch to also disconnect audit consumer.

Preserve all existing code (config loading, logger, server build, plugins, routes, health check). Only ADD the audit consumer initialization.
  </action>
  <verify>
Run `pnpm --filter @splits-network/gpt-service build` and confirm it compiles without errors.
Verify that index.ts imports AuditEventConsumer, creates instance, calls connect(), and handles disconnect in SIGTERM.
  </verify>
  <done>gpt-service startup initializes AuditEventConsumer, connects to RabbitMQ, and gracefully disconnects on shutdown. End-to-end audit event pipeline is wired: EventPublisher (publish) -> RabbitMQ -> AuditEventConsumer (consume) -> gpt_oauth_events table.</done>
</task>

</tasks>

<verification>
1. `pnpm --filter @splits-network/gpt-service build` succeeds
2. audit-consumer.ts exports AuditEventConsumer class
3. AuditEventConsumer binds to gpt.oauth.# and gpt.action.# routing keys
4. AuditEventConsumer writes to gpt_oauth_events table via Supabase insert
5. AuditEventConsumer uses manual ack (noAck: false) for reliable delivery
6. index.ts creates, connects, and disconnects AuditEventConsumer properly
7. SIGTERM handler disconnects both EventPublisher and AuditEventConsumer
</verification>

<success_criteria>
- End-to-end RabbitMQ flow is wired: EventPublisher publishes gpt.oauth.* -> AuditEventConsumer receives -> writes to gpt_oauth_events
- Consumer uses manual acknowledgment (ack on success, nack on failure)
- Graceful shutdown disconnects consumer before closing server
- Build passes without errors
</success_criteria>

<output>
After completion, create `.planning/phases/11-service-foundation/11-03-SUMMARY.md`
</output>

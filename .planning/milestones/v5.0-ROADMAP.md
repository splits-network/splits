# Milestone v5.0: Custom GPT / Applicant Network

**Status:** SHIPPED 2026-02-13
**Phases:** 11-15
**Total Plans:** 18

## Overview

Candidates interact with Applicant.Network via natural language through a Custom GPT in ChatGPT -- search jobs, analyze resumes, check application status, and submit applications.

## Phases

### Phase 11: Service Foundation
**Goal**: gpt-service microservice exists with database tables and configuration, ready for OAuth and endpoint development
**Depends on**: Nothing (first phase of v5.0)
**Requirements**: INFRA-01, INFRA-02, INFRA-03
**Plans**: 3 plans

Plans:
- [x] 11-01: Service scaffold, GPT config loader, health check, EventPublisher
- [x] 11-02: Database migration with 4 GPT OAuth tables and indexes
- [x] 11-03: Audit event consumer for end-to-end RabbitMQ flow

**Success Criteria:**
1. gpt-service starts, passes health check, and responds on its configured port
2. All 4 GPT database tables exist with correct schemas
3. Environment variables for GPT OAuth are loaded and validated on startup

### Phase 12: OAuth2 Provider
**Goal**: Candidates can authenticate via Clerk through the GPT OAuth flow and receive scoped access tokens that gpt-service validates
**Depends on**: Phase 11
**Requirements**: AUTH-01, AUTH-02, AUTH-03, AUTH-04, AUTH-05, AUTH-06, AUTH-07
**Plans**: 6 plans

Plans:
- [x] 12-01: Schema migration (scopes columns) + shared-config ES256 update
- [x] 12-02: OAuth core service (TDD): auth code flow, PKCE, JWT ES256, token rotation, replay detection
- [x] 12-03: api-gateway GPT routing with Clerk auth bypass
- [x] 12-04: OAuth route handlers + JWT validation middleware in gpt-service
- [x] 12-05: Consent page, error page, success flash, learn-more page (candidate app)
- [x] 12-06: Connected Apps management on profile page + Clerk webhook handler

**Success Criteria:**
1. ChatGPT can initiate OAuth2 authorization code flow and user is redirected to Clerk login
2. After Clerk authentication, authorization code is exchanged for access token + refresh token
3. Expired access tokens can be refreshed via refresh token endpoint (with token rotation)
4. Refresh tokens can be revoked, immediately preventing further token issuance
5. api-gateway routes /api/v1/gpt/* requests to gpt-service, bypassing Clerk auth

### Phase 13: GPT API Endpoints
**Goal**: GPT can search jobs, view job details, check application status, submit applications with confirmation safety, and analyze resume fit
**Depends on**: Phase 12
**Requirements**: ENDP-01, ENDP-02, ENDP-03, ENDP-04, ENDP-05, ENDP-06, ENDP-07
**Plans**: 4 plans

Plans:
- [x] 13-01: Foundation layer: types, repository, error helpers, confirmation token store
- [x] 13-02: Read endpoints: job search, job details, application status
- [x] 13-03: Write endpoint: application submission with confirmation safety pattern
- [x] 13-04: Resume analysis endpoint with ai-service integration

**Success Criteria:**
1. Job search returns GPT-formatted results filtered by keywords, location, commute type, and job level
2. Job details endpoint returns comprehensive job info including requirements, pre-screen questions, and company details
3. Application status endpoint returns the authenticated candidate's applications with human-readable status labels
4. Application submission returns CONFIRMATION_REQUIRED on first call, executes on confirmed=true
5. Resume analysis endpoint parses candidate's resume and returns fit score against a job posting

### Phase 14: OpenAPI Schema + GPT Configuration
**Goal**: Complete OpenAPI schema and GPT Instructions document enable configuring a functional Custom GPT
**Depends on**: Phase 13
**Requirements**: CONF-01, CONF-02, CONF-03, CONF-04
**Plans**: 2 plans

Plans:
- [x] 14-01: OpenAPI 3.0.1 schema file and serving endpoint
- [x] 14-02: GPT Instructions document and Builder listing copy

**Success Criteria:**
1. OpenAPI 3.0.1 schema defines all GPT Actions with operationIds, parameter descriptions, and OAuth2 security
2. Schema is served at /api/v1/gpt/openapi.yaml and accepted by GPT Builder
3. GPT Instructions document covers all action scenarios, confirmation rules, and error handling
4. All write operations annotated with x-openai-isConsequential: true

### Phase 15: Production Hardening
**Goal**: gpt-service is production-ready with deployment infrastructure, rate limiting, token lifecycle management, and observability
**Depends on**: Phase 14
**Requirements**: HARD-01, HARD-02, HARD-03, HARD-04
**Plans**: 3 plans

Plans:
- [x] 15-01: Deployment hardening, token cleanup CronJob, Clerk webhook signature verification
- [x] 15-02: GPT-specific per-user tiered rate limiting in api-gateway
- [x] 15-03: Gap closure: fix gateway header forwarding, query string bug, and K8s env vars

**Success Criteria:**
1. Kubernetes deployment manifest exists with 2 replicas
2. GPT-specific per-user rate limits enforced (30 req/min reads, 10 req/min writes)
3. Token cleanup CronJob runs every 6 hours expiring old artifacts
4. All GPT OAuth events and action executions audit-logged via RabbitMQ

---

## Milestone Summary

**Key Decisions:**
- Backend as OAuth provider for GPT (Clerk = identity, backend = OAuth provider, GPT = OAuth client)
- New gpt-service nano-service (dedicated microservice for GPT concerns)
- ES256 asymmetric JWT signing with jose library (over jsonwebtoken)
- PKCE verification with SHA-256 base64url encoding
- Token rotation on every refresh with replay detection (revokes ALL sessions)
- Two-step confirmation safety pattern for all write actions
- In-memory confirmation token store (15-min TTL, acceptable for MVP)
- OpenAPI 3.0.1 (not 3.1) for GPT Builder compatibility
- Dual-auth pattern: GPT Bearer tokens OR x-gpt-clerk-user-id header
- Route-level @fastify/rate-limit config overrides for tiered rate limiting

**Issues Resolved:**
- Gateway authorize endpoint dropping x-clerk-user-id header (CRITICAL, fixed in 15-03)
- Wildcard GET route double-appending query string (MODERATE, fixed in 15-03)
- GPT_SERVICE_URL missing from api-gateway K8s deployment (MODERATE, fixed in 15-03)
- INTERNAL_SERVICE_KEY missing from gpt-service K8s deployment (MINOR, fixed in 15-03)
- CryptoKey type incompatibility with Node.js (fixed: KeyLike from jose)
- FastifyBaseLogger vs pino Logger type mismatch (fixed: cast)

**Technical Debt Incurred:**
- In-memory confirmation token store (tokens lost on restart, acceptable for 15-min TTL)
- Manual GPT Builder configuration required (one-time setup, documented)

---
*For current project status, see .planning/ROADMAP.md*

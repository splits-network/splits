# AI Service - Copilot Instructions

These instructions are specific to the **AI Service** and should be used in addition to the main repository copilot instructions.

## Service Overview

This service provides **centralized AI capabilities** for the Splits Network platform, with a primary focus on candidate-job fit analysis using OpenAI's GPT models.

### Key Responsibilities
- Generate AI-powered candidate-job fit reviews with confidence scores
- Analyze resume text against job requirements for quality matching
- Publish completion events for workflow automation
- Provide explainable AI decisions with reasoning

## Architecture Patterns

### ✅ V2 Architecture Compliance
This service follows **V2 architecture patterns**:
- Repository pattern with `resolveAccessContext(supabase, clerkUserId)`
- Event-driven architecture with RabbitMQ publishing
- Direct Supabase queries for data access
- Standardized 5-route pattern: LIST, GET, CREATE, UPDATE, DELETE
- Domain-based folder structure: `src/v2/reviews/`

### Event-Driven Integration
```typescript
// Event Flow Pattern  
application.created → AI analysis → ai_review.completed → downstream automation
```

**Critical**: This service operates **asynchronously** and should never block application submissions.

## Code Patterns

### AI Review Creation Pattern
```typescript
// Always check for document text availability
const documents = await this.getApplicationDocuments(applicationId);
const resumeDocument = documents.find(d => d.document_type === 'resume');

if (!resumeDocument?.metadata?.extracted_text) {
  logger.warn('No resume text available for AI analysis');
  // Gracefully handle missing text - don't fail
  return this.createMinimalReview(application);
}
```

### OpenAI Integration Pattern
```typescript
// Use structured prompts with clear instructions
const completion = await openai.chat.completions.create({
  model: "gpt-4",
  messages: [
    {
      role: "system", 
      content: "You are an expert recruiter analyzing candidate-job fit..."
    },
    {
      role: "user",
      content: `Analyze this candidate against the job requirements:\n\n${prompt}`
    }
  ],
  temperature: 0.3, // Lower for consistent analysis
  max_tokens: 2000
});
```

### Error Handling Pattern
```typescript
// Always publish failure events for observability
catch (error) {
  await this.eventPublisher.publish('ai_review.failed', {
    application_id: applicationId,
    error_type: error.name,
    error_message: error.message,
    failed_at: new Date().toISOString()
  });
  throw error;
}
```

## Critical Implementation Details

### Document Text Dependency
**CRITICAL**: This service depends on document-processing-service for text extraction:
- AI reviews require `document.metadata.extracted_text` from resumes
- Always check for text availability before analysis
- Gracefully handle missing text (fallback to job description only)
- Never assume document text is available immediately after upload

### AI Review Scoring System
```typescript
interface AIReviewScore {
  fit_score: number;           // 0-100 overall fit
  confidence: number;          // 0-100 confidence in analysis
  recommendation: 'good_fit' | 'poor_fit' | 'review_recommended';
  reasoning: string;           // Explainable AI reasoning
}
```

### Event Publishing Requirements
```typescript
// Always publish completion events
await this.eventPublisher.publish('ai_review.completed', {
  review_id: review.id,
  application_id: application.id,
  candidate_id: application.candidate_id,
  job_id: application.job_id,
  fit_score: review.fit_score,
  recommendation: review.recommendation,
  analysis_completed_at: new Date().toISOString()
});
```

## Database Schema Interaction

### Table: `ai.reviews`
```sql
-- Primary AI review storage
id UUID PRIMARY KEY
application_id UUID REFERENCES ats.applications(id)
fit_score INTEGER CHECK (fit_score >= 0 AND fit_score <= 100)
confidence INTEGER CHECK (confidence >= 0 AND confidence <= 100)
recommendation TEXT CHECK (recommendation IN ('good_fit', 'poor_fit', 'review_recommended'))
analysis JSONB -- Full AI response and reasoning
created_at TIMESTAMP DEFAULT NOW()
```

### Access Context Usage
```typescript
// Reviews are scoped by application access
const context = await resolveAccessContext(this.supabase, clerkUserId);

// Filter reviews based on accessible applications
if (context.candidateId) {
  // Candidates see their own reviews
  const applications = await this.getApplicationsByCandidate(context.candidateId);
  query.in('application_id', applications.map(a => a.id));
} else if (context.organizationIds?.length) {
  // Company users see reviews for their jobs
  const jobIds = await this.getJobsByOrganization(context.organizationIds);
  const applications = await this.getApplicationsByJobs(jobIds);
  query.in('application_id', applications.map(a => a.id));
}
```

## OpenAI Integration Guidelines

### API Usage Patterns
```typescript
// Always include error handling and retries
const MAX_RETRIES = 3;
let attempt = 0;

while (attempt < MAX_RETRIES) {
  try {
    const response = await openai.chat.completions.create({
      model: "gpt-4",
      messages: promptMessages,
      temperature: 0.3,
      max_tokens: 2000
    });
    break;
  } catch (error) {
    attempt++;
    if (attempt >= MAX_RETRIES) throw error;
    await new Promise(resolve => setTimeout(resolve, 1000 * attempt));
  }
}
```

### Prompt Engineering Best Practices
- Use system messages to establish context and role
- Provide structured examples in few-shot learning
- Request structured output (JSON) for consistent parsing
- Include clear scoring criteria and reasoning requirements
- Limit response length to control costs

### Cost Management
- Monitor token usage per request
- Implement rate limiting for bulk operations  
- Cache common analysis patterns where possible
- Use lower-cost models for simple classifications

## Event Specifications

### Consumed: `application.created`
**Source**: ats-service
**Trigger**: When candidate submits new application
**Action**: Generate AI fit analysis

**Payload Requirements**:
```typescript
{
  application_id: string;
  candidate_id: string;
  job_id: string;
  submitted_at: string;
}
```

### Published: `ai_review.completed`
**Trigger**: Successful AI analysis completion
**Consumers**: automation-service (workflow triggers), notification-service (alerts)

**Payload Structure**:
```typescript
{
  review_id: string;
  application_id: string;
  candidate_id: string;
  job_id: string;
  fit_score: number;         // 0-100
  recommendation: string;    // 'good_fit' | 'poor_fit' | 'review_recommended' 
  confidence: number;        // 0-100
  analysis_completed_at: string;
}
```

## Testing Guidelines

### Unit Testing Patterns
```typescript
// Mock OpenAI responses for consistent testing
jest.mock('openai', () => ({
  chat: {
    completions: {
      create: jest.fn().mockResolvedValue({
        choices: [{ message: { content: 'mock AI response' } }]
      })
    }
  }
}));
```

### Integration Testing
- Test with real document text samples
- Verify event publishing works correctly
- Test error handling and retry logic
- Validate access context filtering

## Performance Considerations

### Async Processing Requirements
- AI analysis can take 10-30 seconds per review
- Process reviews asynchronously via events
- Implement queue management for bulk operations
- Monitor processing times and failures

### Monitoring & Observability
- Track AI review completion rates
- Monitor OpenAI API costs and token usage
- Alert on high failure rates or slow processing
- Log fit score distributions for quality assessment

## Common Pitfalls

❌ **Don't block applications**: AI reviews run async, don't delay application submissions  
❌ **Don't assume document text exists**: Always check for extracted text availability  
❌ **Don't ignore API rate limits**: Implement proper retry and backoff strategies  
❌ **Don't skip error events**: Always publish failure events for observability  

✅ **Do use structured prompts**: Consistent prompt structure improves AI output quality  
✅ **Do validate AI responses**: Parse and validate AI output before storing  
✅ **Do publish completion events**: Enable downstream workflow automation  
✅ **Do implement cost controls**: Monitor and limit OpenAI API usage  

## Future Expansion Areas

- **Candidate Matching**: AI-powered job recommendations
- **Content Generation**: Automated job descriptions and summaries  
- **Fraud Detection**: Anomaly detection in applications
- **Sentiment Analysis**: Communication tone analysis

---

**Last Updated**: January 2, 2026  
**Service Version**: 1.0.0  
**Architecture**: V2  
**AI Model**: GPT-4
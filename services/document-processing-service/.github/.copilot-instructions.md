# Document Processing Service - Copilot Instructions

These instructions are specific to the **Document Processing Service** and should be used in addition to the main repository copilot instructions.

## Service Overview

This service is responsible for **asynchronous document text extraction** from uploaded files. It processes documents triggered by RabbitMQ events and stores extracted text for AI analysis.

### Key Responsibilities
- Listen for `document.uploaded` events from document-service
- Extract text from PDF and DOCX documents using `pdf-parse` and `mammoth`
- Store extracted text in `metadata.extracted_text` (JSONB field)
- Update processing status: pending → processing → processed/failed
- Publish completion events for downstream services

## Architecture Patterns

### ✅ V2 Architecture Compliance
This service follows **V2 architecture patterns**:
- Repository pattern with `resolveAccessContext(supabase, clerkUserId)`
- Single PATCH method for all document updates
- Direct Supabase queries with role-based filtering
- Event-driven coordination (no HTTP service calls)
- Domain-based folder structure: `src/v2/documents/`

### Event-Driven Processing
```typescript
// Event Flow Pattern
document.uploaded → text extraction → metadata update → document.processed
```

**Critical**: This service operates **asynchronously** and should never block document uploads. Text extraction happens in the background.

## Code Patterns

### Text Extraction Pattern
```typescript
// Always store extracted text in metadata.extracted_text
const extractedText = await extractor.extractText(documentBuffer, mimeType);
await repository.updateDocument(id, clerkUserId, {
  processing_status: 'processed',
  metadata: {
    ...existingMetadata,
    extracted_text: extractedText,
    text_length: extractedText.length
  }
});
```

### Error Handling Pattern
```typescript
// Always update status to 'failed' with error details
catch (error) {
  await repository.updateDocument(id, clerkUserId, {
    processing_status: 'failed',
    processing_error: error.message
  });
  await eventPublisher.publish('document.failed', { ... });
}
```

### Access Context Usage
```typescript
// V2 Pattern - supabase client first, clerk ID second
const context = await resolveAccessContext(this.supabase, clerkUserId);

// Filter by access context
if (context.candidateId) {
  query.eq('user_id', context.candidateId);
} else if (context.organizationIds?.length) {
  query.in('company_id', context.organizationIds);
}
```

## Critical Implementation Details

### Document Text Extraction Bug Fix
This service was created to fix the critical AI review blocking issue:
- **Problem**: AI service expected `document.extracted_text` property but schema stores text in `document.metadata.extracted_text`
- **Solution**: This service processes documents and populates `metadata.extracted_text` correctly
- **Impact**: Enables AI reviews to access resume text for candidate-job fit analysis

### Supported File Types
```typescript
const SUPPORTED_TYPES = [
  'application/pdf',           // PDF documents
  'application/msword',        // DOC files  
  'application/vnd.openxmlformats-officedocument.wordprocessingml.document' // DOCX files
];
```

### Processing Status Flow
```
pending (initial) → processing (active) → processed/failed (final)
```

## Event Specifications

### Consumed: `document.uploaded`
**Source**: document-service  
**Trigger**: When user uploads any document  
**Action**: Start text extraction pipeline

### Published: `document.processed`
**Trigger**: Successful text extraction completion  
**Consumers**: ai-service (for reviews), automation-service (for analysis)

### Published: `document.failed` 
**Trigger**: Text extraction failure  
**Purpose**: Error tracking and retry logic

## Database Schema Interaction

### Table: `documents`
```sql
metadata JSONB DEFAULT '{}' -- Store extracted text here
processing_status processing_status DEFAULT 'pending'
processing_error TEXT -- Store failure details
```

### Critical Field Access
```typescript
// ✅ CORRECT - Access extracted text from metadata
const text = document.metadata?.extracted_text;

// ❌ WRONG - Don't expect direct property
const text = document.extracted_text; // This doesn't exist!
```

## Dependencies & Integration

### Required Services
- **RabbitMQ**: Event consumption and publishing
- **Supabase**: Document storage and metadata updates
- **Document Service**: Source of upload events

### Optional Integrations
- **AI Service**: Consumes extracted text for reviews
- **Automation Service**: Uses text for analysis and matching

## Development Guidelines

### Testing Patterns
```typescript
// Test with real document buffers
const pdfBuffer = await fs.readFile('test-resume.pdf');
const result = await textExtractor.extractText(pdfBuffer, 'application/pdf');
expect(result.text).toContain('expected content');
```

### Monitoring & Observability
- Track processing times via `processing_time_ms`
- Monitor failure rates by `processing_status: 'failed'`
- Alert on queue backlog (pending documents)

### Performance Considerations
- Process documents in batches of 5-10 to avoid memory issues
- Implement circuit breaker for failing document types
- Add timeout limits for large document processing

## Common Pitfalls

❌ **Don't block uploads**: This service runs async, uploads should complete immediately  
❌ **Don't make HTTP calls to other services**: Use direct database queries and events only  
❌ **Don't ignore metadata structure**: Always use `metadata.extracted_text`, not direct properties  
❌ **Don't skip error handling**: Always update processing_status on failures  

✅ **Do use batch processing**: Handle multiple pending documents efficiently  
✅ **Do publish completion events**: Enable downstream service coordination  
✅ **Do validate extraction quality**: Check text length and content validity  
✅ **Do handle retroactive processing**: Process existing pending documents on startup  

---

**Last Updated**: January 2, 2026  
**Service Version**: 1.0.0  
**Architecture**: V2